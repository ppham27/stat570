{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rats = pd.DataFrame({\n",
    "    'contaminant': [\n",
    "        6.1, 4.2, 0.5, 8.8, 1.5, 9.2, 8.5, 8.7, 6.7, 6.5, 6.3, 6.7, 0.2, 8.7, 7.5,\n",
    "    ],\n",
    "    'survival_time': [\n",
    "        0.8, 3.5, 12.4, 1.1, 8.9, 2.4, 0.1, 0.4, 3.5, 8.3, 2.6, 1.5, 16.6, 0.1, 1.3,\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.82115025,  0.30133576])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import root\n",
    "\n",
    "def estimate_beta(x: np.array, y: np.array) -> np.array:\n",
    "    \"\"\"Estimate beta using MLE under exponential regression model.\n",
    "    \"\"\"\n",
    "    assert len(x) == len(y), 'x and y shoud have the same length.'\n",
    "    \n",
    "    def score(beta):\n",
    "        beta_0 = beta[0]\n",
    "        beta_1 = beta[1]\n",
    "        return np.array([\n",
    "            len(x) - np.sum(y*np.exp(x*beta_1))*np.exp(beta_0),\n",
    "            np.sum(x) - np.sum(x*y*np.exp(x*beta_1))*np.exp(beta_0)\n",
    "        ])\n",
    "    \n",
    "    return root(score, np.array([-2.8, 0.3]))['x']\n",
    "    \n",
    "beta_hat = estimate_beta(rats['contaminant'].values, rats['survival_time'].values)\n",
    "beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30133576292327585"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_hat[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 15.  ,  90.1 ],\n",
       "       [ 90.1 , 671.07]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import linalg\n",
    "\n",
    "def compute_fisher_information(x: np.array, y: np.array) -> np.array:\n",
    "    \"\"\"Computes the Fisher information.\n",
    "    \n",
    "    Usually, it would depend on beta, but in this case, it cancels out.\n",
    "    \"\"\"\n",
    "    assert len(x) == len(y), 'x and y shoud have the same length.'\n",
    "    return np.array([\n",
    "        [len(x), np.sum(x)],\n",
    "        [np.sum(x), np.sum(x*x)]])\n",
    "\n",
    "fisher_information = compute_fisher_information(\n",
    "    rats['contaminant'].values, rats['survival_time'].values)\n",
    "fisher_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34448471, -0.04625162],\n",
       "       [-0.04625162,  0.00770005]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_hat_variance = linalg.cho_solve(\n",
    "    linalg.cho_factor(fisher_information), np.eye(len(beta_hat)))\n",
    "beta_hat_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'status'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6694f7e276dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconfidence_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_hat_variance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfidence_range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'status'"
     ]
    }
   ],
   "source": [
    "from scipy import status\n",
    "\n",
    "confidence_range = np.sqrt(np.diag(beta_hat_variance))*stats.norm.isf((1-0.95)/2)\n",
    "confidence_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(beta_hat - confidence_range)\n",
    "print(beta_hat + confidence_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Tuple\n",
    "\n",
    "def make_log_likelihood(x: np.array, y: np.array) -> Callable[[np.array], float]:\n",
    "    def log_likelihood(beta: np.array) -> float:\n",
    "        beta_0 = beta[0]\n",
    "        beta_1 = beta[1]\n",
    "        return len(x)*beta_0 + np.sum(x)*beta_1 - np.exp(beta_0)*np.sum(y*np.exp(beta_1*x))\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "ax = fig.gca()\n",
    "\n",
    "def plot_log_likelihood(\n",
    "    ax: plt.Axes, mesh_grid: Tuple[np.array, np.array],\n",
    "    x: np.array, y: np.array) -> matplotlib.contour.QuadContourSet:    \n",
    "    betas = np.stack(mesh_grid, axis=-1)\n",
    "    \n",
    "    log_likelihood = np.vectorize(\n",
    "        make_log_likelihood(x, y), signature='(2)->()')(betas)\n",
    "    \n",
    "    contour_set = ax.contourf(\n",
    "        mesh_grid[0], mesh_grid[1], log_likelihood,\n",
    "        levels=256, cmap=plt.cm.YlOrRd,\n",
    "        norm=matplotlib.colors.PowerNorm(gamma=10))\n",
    "    ax.set_xlabel('$\\\\beta_0$')\n",
    "    ax.set_ylabel('$\\\\beta_1$')\n",
    "    ax.set_title('Log-Likelihood Function')\n",
    "    return contour_set\n",
    "\n",
    "mesh_grid = np.meshgrid(\n",
    "    np.linspace(beta_hat[0] - 1.1*confidence_range[0],\n",
    "                beta_hat[0] + 1.1*confidence_range[0], 100),\n",
    "    np.linspace(beta_hat[1] - 1.1*confidence_range[1],\n",
    "                beta_hat[1] + 1.1*confidence_range[1], 100))\n",
    "    \n",
    "contour_set = plot_log_likelihood(ax,\n",
    "                    mesh_grid,\n",
    "                    rats['contaminant'].values,\n",
    "                    rats['survival_time'].values)\n",
    "fig.colorbar(contour_set, spacing='proportional',\n",
    "             ticks=[-130, -52, -44, -40, -38, -36, -34, -32, -30]);\n",
    "fig.savefig('p2_log_likelihood.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,4))\n",
    "ax = fig.gca()\n",
    "\n",
    "def plot_asymptotic_normal(\n",
    "    ax: plt.Axes, mesh_grid: Tuple[np.array, np.array],\n",
    "    dist) -> matplotlib.contour.QuadContourSet: \n",
    "    betas = np.stack(mesh_grid, axis=-1)\n",
    "    \n",
    "    log_likelihood = np.vectorize(\n",
    "        dist.logpdf, signature='(2)->()')(betas)\n",
    "    \n",
    "    contour_set = ax.contourf(\n",
    "        mesh_grid[0], mesh_grid[1], log_likelihood,\n",
    "        levels=256, cmap=plt.cm.YlGnBu,\n",
    "        norm=matplotlib.colors.PowerNorm(gamma=10))\n",
    "    ax.set_xlabel('$\\\\beta_0$')\n",
    "    ax.set_ylabel('$\\\\beta_1$')\n",
    "    ax.set_title('Asymptotic Normal Distribution')\n",
    "    return contour_set\n",
    "\n",
    "asymptotic_normal = stats.multivariate_normal(\n",
    "    mean=beta_hat, cov=beta_hat_variance)\n",
    "contour_set = plot_asymptotic_normal(ax, mesh_grid, asymptotic_normal)\n",
    "fig.colorbar(contour_set, spacing='proportional',\n",
    "             ticks=[-36, -8, -4, -2, -1, 0, 1, 2]);\n",
    "fig.savefig('p2_asymptotic_normal.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
