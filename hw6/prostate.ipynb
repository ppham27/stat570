{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  res = PandasDataFrame.from_items(items)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lcavol   lweight   age      lbph  svi       lcp  gleason  pgg45      lpsa\n",
       "0 -0.579818  2.769459  50.0 -1.386294  0.0 -1.386294      6.0    0.0 -0.430783\n",
       "1 -0.994252  3.319626  58.0 -1.386294  0.0 -1.386294      6.0    0.0 -0.162519\n",
       "2 -0.510826  2.691243  74.0 -1.386294  0.0 -1.386294      7.0   20.0 -0.162519\n",
       "3 -1.203973  3.282789  58.0 -1.386294  0.0 -1.386294      6.0    0.0 -0.162519\n",
       "4  0.751416  3.432373  62.0 -1.386294  0.0 -1.386294      6.0    0.0  0.371564"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import prostate\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "prostate.load_data().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from stat570.mcmc import gibbs_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'stat570.mcmc.gibbs_sampling' from '/local/stat570/mcmc/gibbs_sampling.py'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(gibbs_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prostate_input_fn():\n",
    "    data = prostate.load_data()\n",
    "    features = data.to_dict('list')\n",
    "    labels = features.pop('lpsa')\n",
    "    return tf.data.Dataset.from_tensors((features, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'stat570'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-711-7e01499c104d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#from stat570.mcmc.gibbs_sampling import GibbsSamplingKernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstat570\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'stat570'"
     ]
    }
   ],
   "source": [
    "#from stat570.mcmc.gibbs_sampling import GibbsSamplingKernel\n",
    "import stat570"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "GibbsSamplingKernelResults = collections.namedtuple(\n",
    "    'GibbsSamplingKernelResults',\n",
    "    [\n",
    "        'log_acceptance_correction',\n",
    "        'target_log_prob',\n",
    "        'steps_completed',\n",
    "    ])\n",
    "\n",
    "class GibbsSamplingKernel(tfp.mcmc.TransitionKernel):\n",
    "    \"\"\"Makes a transition kernel that does sequential Gibbs sampling.\n",
    "    \n",
    "    Args:\n",
    "      samplers: A list of samplers that take a slice of state and return a\n",
    "        distribution.\n",
    "      target_log_prob_fn: A function to compute the log probability of state.            \n",
    "    \"\"\"\n",
    "    def __init__(self, samplers, target_log_prob_fn,\n",
    "                 name='gibbs_sampling_kernel'):\n",
    "        self._name = name\n",
    "        self._samplers = samplers\n",
    "        self._target_log_prob_fn = target_log_prob_fn\n",
    "    \n",
    "    def one_step(self, current_state, previous_kernel_results):\n",
    "        def update_state(current_state, i):\n",
    "            head, tail = current_state[:i], current_state[(i + 1):]\n",
    "            return head + [self._samplers[i](*(head + tail)).sample()] + tail        \n",
    "        \n",
    "        num_samplers = len(self._samplers)\n",
    "        steps_completed = previous_kernel_results.steps_completed\n",
    "        pred_fn_pairs = [\n",
    "            (tf.equal(tf.mod(steps_completed, num_samplers), i),\n",
    "             functools.partial(update_state, current_state, i))\n",
    "            for i in range(num_samplers)]\n",
    "        next_state = tf.case(pred_fn_pairs)\n",
    "        \n",
    "        target_log_prob = self._target_log_prob_fn(*next_state)        \n",
    "        kernel_results = GibbsSamplingKernelResults(\n",
    "            target_log_prob=target_log_prob,\n",
    "            log_acceptance_correction=(\n",
    "                -target_log_prob + previous_kernel_results.target_log_prob),\n",
    "            steps_completed=steps_completed + 1)\n",
    "        \n",
    "        return next_state, kernel_results\n",
    "    \n",
    "    def bootstrap_results(self, init_state):\n",
    "        with tf.name_scope(\n",
    "            '_'.join([self._name, 'bootstrap_results']),\n",
    "            values=init_state):\n",
    "            target_log_prob = self._target_log_prob_fn(*init_state)\n",
    "            return GibbsSamplingKernelResults(\n",
    "                log_acceptance_correction=tf.zeros_like(target_log_prob),\n",
    "                target_log_prob=target_log_prob,\n",
    "                steps_completed=tf.constant(0, dtype=tf.int64))\n",
    "    \n",
    "    @property\n",
    "    def is_calibrated(self):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inverse_error_variance_dist(\n",
    "    prior_concentration, prior_rate, features, labels, beta):\n",
    "    with tf.name_scope('make_inverse_error_variance_dist', \n",
    "                       values=[\n",
    "                           prior_concentration,\n",
    "                           prior_rate,\n",
    "                           features,\n",
    "                           labels,\n",
    "                           beta,\n",
    "                       ]):\n",
    "        posterior_concentration = (\n",
    "            prior_concentration +\n",
    "            tf.divide(tf.cast(tf.shape(features)[0], tf.float32), 2.))\n",
    "        posterior_rate = (prior_rate +\n",
    "                          tf.nn.l2_loss(labels - tf.tensordot(features, beta, 1)))\n",
    "        \n",
    "        return tf.distributions.Gamma(\n",
    "            concentration=posterior_concentration, rate=posterior_rate,\n",
    "            name='posterior_inverse_error_variance')\n",
    "    \n",
    "def make_beta_dist(prior_mean, prior_variance, features, labels, inverse_error_variance):\n",
    "    shape = int(prior_mean.shape[0])\n",
    "    with tf.name_scope('make_beta_dist',\n",
    "                       values=[\n",
    "                           inverse_error_variance,\n",
    "                           features,\n",
    "                           labels,\n",
    "                           prior_mean,\n",
    "                           prior_variance,\n",
    "                       ]):\n",
    "        transposed_features = tf.transpose(features)\n",
    "        gramian_matrix = tf.matmul(transposed_features, features)\n",
    "        mle_mean = tf.squeeze(tf.linalg.cholesky_solve(\n",
    "            tf.linalg.cholesky(gramian_matrix),\n",
    "            tf.matmul(transposed_features, tf.expand_dims(labels, -1))))\n",
    "        mle_precision = gramian_matrix*inverse_error_variance            \n",
    "        \n",
    "        posterior_precision = mle_precision + tf.eye(shape)/prior_variance\n",
    "        posterior_covariance = tf.linalg.cholesky_solve(\n",
    "            tf.linalg.cholesky(posterior_precision), tf.eye(shape))\n",
    "        \n",
    "        posterior_mean = tf.tensordot(\n",
    "            tf.matmul(posterior_covariance, mle_precision),\n",
    "            mle_mean - prior_mean, axes=1) + prior_mean\n",
    "        \n",
    "        return tfp.distributions.MultivariateNormalFullCovariance(\n",
    "            loc=posterior_mean, covariance_matrix=posterior_covariance,\n",
    "            name='posterior_beta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params, config):\n",
    "    del config\n",
    "    \n",
    "    prior_inverse_error_variance_concentration = (\n",
    "        params['prior']['inverse_error_variance']['concentration'])\n",
    "    prior_inverse_error_variance_rate = (\n",
    "        params['prior']['inverse_error_variance']['rate'])\n",
    "        \n",
    "    prior_beta_mean = tf.constant(params['prior']['beta']['mean'],\n",
    "                                  dtype=tf.float32)\n",
    "    prior_beta_variance = tf.constant(params['prior']['beta']['variance'],\n",
    "                                      dtype=tf.float32)\n",
    "    \n",
    "    def forward(features):\n",
    "        inverse_error_variance = tfp.edward2.Gamma(\n",
    "            concentration=prior_inverse_error_variance_concentration,\n",
    "            rate=prior_inverse_error_variance_rate,\n",
    "            name='inverse_error_variance')\n",
    "    \n",
    "        beta = tfp.edward2.MultivariateNormalDiag(\n",
    "            loc=prior_beta_mean,\n",
    "            scale_identity_multiplier=tf.sqrt(prior_beta_variance), name='beta')\n",
    "        \n",
    "        return tfp.edward2.Normal(\n",
    "            loc=tf.tensordot(features, beta, axes=1), scale=1/tf.sqrt(inverse_error_variance),\n",
    "            name='labels')\n",
    "    \n",
    "    features = tf.feature_column.input_layer(\n",
    "        features, [tf.feature_column.numeric_column('lcavol')])\n",
    "    features = tf.concat((tf.ones_like(features), features), axis=-1)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return forward(features).value\n",
    "    \n",
    "    log_joint_fn = functools.partial(\n",
    "        tfp.edward2.make_log_joint_fn(lambda: forward(features)),\n",
    "        labels=labels)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return log_joint_fn(labels=labels) # currently will error\n",
    "    \n",
    "    make_inverse_error_variance_dist_fn = functools.partial(\n",
    "        make_inverse_error_variance_dist,\n",
    "        prior_inverse_error_variance_concentration,\n",
    "        prior_inverse_error_variance_rate,\n",
    "        features, labels)\n",
    "    \n",
    "    make_beta_dist_fn = functools.partial(\n",
    "        make_beta_dist, prior_beta_mean, prior_beta_variance, features, labels)\n",
    "        \n",
    "    kernel = tfp.mcmc.MetropolisHastings(\n",
    "        inner_kernel=gibbs_sampling.GibbsSamplingKernel(\n",
    "            samplers=[\n",
    "                make_inverse_error_variance_dist_fn,\n",
    "                make_beta_dist_fn,\n",
    "            ],\n",
    "            target_log_prob_fn=lambda inverse_error_variance, beta: log_joint_fn(\n",
    "                inverse_error_variance=inverse_error_variance,\n",
    "                beta=beta)))\n",
    "    \n",
    "    samples, _ = tfp.mcmc.sample_chain(\n",
    "        num_results=params['mcmc']['num_results'],\n",
    "        current_state=(\n",
    "            params['mcmc']['initial_state']['inverse_error_variance'],\n",
    "            params['mcmc']['initial_state']['beta']),\n",
    "        kernel=kernel,\n",
    "        num_burnin_steps=500,\n",
    "        num_steps_between_results=1,  # One less the number of samplers.\n",
    "        parallel_iterations=1)\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  res = PandasDataFrame.from_items(items)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  return _inspect.getargspec(target)\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_PARAMS = {\n",
    "    'prior': {\n",
    "        'inverse_error_variance': {\n",
    "            'concentration': 0.01,  # Also called shape and denoted alpha\n",
    "            'rate': 0.01,  # Usually denoted by beta.\n",
    "        },\n",
    "        'beta': {\n",
    "            'mean': [0., 0.],\n",
    "            'variance': 2.,  # Enforce equal variance and no covariance.\n",
    "        },\n",
    "    },\n",
    "    'mcmc': {\n",
    "        'num_results': 2048,\n",
    "        'initial_state': {\n",
    "            'inverse_error_variance': 1.,\n",
    "            'beta': [0., 0.],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    features, labels = prostate_input_fn().repeat().make_one_shot_iterator().get_next()\n",
    "    states_op = model_fn(\n",
    "        features, labels,\n",
    "        tf.estimator.ModeKeys.TRAIN, DEFAULT_PARAMS, tf.estimator.RunConfig())    \n",
    "    init_op = tf.group(tf.global_variables_initializer())\n",
    "graph.finalize()\n",
    "\n",
    "with graph.as_default(), tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    states = sess.run(states_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6162782\n",
      "[1.4999154 0.721838 ]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(states[0]))\n",
    "print(np.mean(states[1], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kernel_results.is_accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3]\n",
      "[ 3  7 10 14 17 21 24 28 31]\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():    \n",
    "    #chain_step = tf.assign_add(chain_step, 1)\n",
    "    chain_step = tf.get_variable('chain_step', shape=(), dtype=tf.int64,\n",
    "                                 initializer=tf.zeros_initializer(),\n",
    "                                 trainable=False, use_resource=True)\n",
    "    def next_state(state, elem):        \n",
    "        _chain_step = tf.assign_add(chain_step, 1)\n",
    "        return state + tf.cond(\n",
    "            tf.equal(tf.mod(_chain_step, 2), 0),\n",
    "            lambda: tf.constant(4), lambda: tf.constant(3))\n",
    "    \n",
    "    states = tf.scan(next_state,\n",
    "                     elems=tf.range(start=1, limit=10, delta=1),\n",
    "                     initializer=0, parallel_iterations=1)\n",
    "    \n",
    "    tmp = tf.one_hot(indices=0,\n",
    "                     depth=50,\n",
    "                     on_value=tf.constant(1 + 10, dtype=tf.int64),\n",
    "                     off_value=tf.constant(1 + 2, dtype=tf.int64),\n",
    "                     dtype=tf.int64)\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()\n",
    "graph.finalize()\n",
    "\n",
    "with graph.as_default(), tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(tmp))\n",
    "    #print(sess.run(tmp))\n",
    "    #res = sess.run(predictions)\n",
    "    #res = sess.run(log_likelihood)\n",
    "    #for i in range(10):\n",
    "        #print(sess.run(next_state))\n",
    "    print(sess.run(states))\n",
    "    print(sess.run(chain_step))\n",
    "    print(sess.run(chain_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = res[1]\n",
    "filtered.is_accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8227994 , 0.5643822 ],\n",
       "       [1.2205217 , 0.88387203],\n",
       "       [1.441134  , 0.7112676 ],\n",
       "       [1.8741407 , 0.4992837 ],\n",
       "       [1.2739804 , 0.890952  ],\n",
       "       [1.2654287 , 0.7994256 ]], dtype=float32)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0][1][filtered.is_accepted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1572111, 1.3124188, 1.0694737, 1.5457894, 1.3813009, 1.5125797],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0][0][filtered.is_accepted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6063379"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4938455 , 0.72335094], dtype=float32)"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.835653  , 0.57863265], dtype=float32)"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res[0][1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.5798185 ],\n",
       "       [ 1.        , -0.99425226],\n",
       "       [ 1.        , -0.51082563],\n",
       "       [ 1.        , -1.2039728 ],\n",
       "       [ 1.        ,  0.7514161 ],\n",
       "       [ 1.        , -1.0498221 ],\n",
       "       [ 1.        ,  0.7371641 ],\n",
       "       [ 1.        ,  0.6931472 ],\n",
       "       [ 1.        , -0.7765288 ],\n",
       "       [ 1.        ,  0.22314355],\n",
       "       [ 1.        ,  0.25464222],\n",
       "       [ 1.        , -1.3470737 ],\n",
       "       [ 1.        ,  1.6134299 ],\n",
       "       [ 1.        ,  1.4770488 ],\n",
       "       [ 1.        ,  1.2059708 ],\n",
       "       [ 1.        ,  1.541159  ],\n",
       "       [ 1.        , -0.41551545],\n",
       "       [ 1.        ,  2.2884862 ],\n",
       "       [ 1.        , -0.56211895],\n",
       "       [ 1.        ,  0.18232156],\n",
       "       [ 1.        ,  1.1474024 ],\n",
       "       [ 1.        ,  2.059239  ],\n",
       "       [ 1.        , -0.54472715],\n",
       "       [ 1.        ,  1.7817091 ],\n",
       "       [ 1.        ,  0.3852624 ],\n",
       "       [ 1.        ,  1.446919  ],\n",
       "       [ 1.        ,  0.51282364],\n",
       "       [ 1.        , -0.40047756],\n",
       "       [ 1.        ,  1.0402768 ],\n",
       "       [ 1.        ,  2.4096441 ],\n",
       "       [ 1.        ,  0.28517893],\n",
       "       [ 1.        ,  0.18232156],\n",
       "       [ 1.        ,  1.2753628 ],\n",
       "       [ 1.        ,  0.00995033],\n",
       "       [ 1.        , -0.01005034],\n",
       "       [ 1.        ,  1.3083328 ],\n",
       "       [ 1.        ,  1.4231083 ],\n",
       "       [ 1.        ,  0.45742485],\n",
       "       [ 1.        ,  2.6609585 ],\n",
       "       [ 1.        ,  0.79750717],\n",
       "       [ 1.        ,  0.6205765 ],\n",
       "       [ 1.        ,  1.442202  ],\n",
       "       [ 1.        ,  0.5822156 ],\n",
       "       [ 1.        ,  1.7715567 ],\n",
       "       [ 1.        ,  1.4861397 ],\n",
       "       [ 1.        ,  1.6639261 ],\n",
       "       [ 1.        ,  2.7278528 ],\n",
       "       [ 1.        ,  1.1631508 ],\n",
       "       [ 1.        ,  1.7457155 ],\n",
       "       [ 1.        ,  1.22083   ],\n",
       "       [ 1.        ,  1.0919234 ],\n",
       "       [ 1.        ,  1.660131  ],\n",
       "       [ 1.        ,  0.51282364],\n",
       "       [ 1.        ,  2.1270406 ],\n",
       "       [ 1.        ,  3.1535904 ],\n",
       "       [ 1.        ,  1.2669476 ],\n",
       "       [ 1.        ,  0.97455966],\n",
       "       [ 1.        ,  0.46373403],\n",
       "       [ 1.        ,  0.5423243 ],\n",
       "       [ 1.        ,  1.0612565 ],\n",
       "       [ 1.        ,  0.45742485],\n",
       "       [ 1.        ,  1.9974177 ],\n",
       "       [ 1.        ,  2.775709  ],\n",
       "       [ 1.        ,  2.0347056 ],\n",
       "       [ 1.        ,  2.0731719 ],\n",
       "       [ 1.        ,  1.4586151 ],\n",
       "       [ 1.        ,  2.0228713 ],\n",
       "       [ 1.        ,  2.1983352 ],\n",
       "       [ 1.        , -0.4462871 ],\n",
       "       [ 1.        ,  1.1939225 ],\n",
       "       [ 1.        ,  1.8640801 ],\n",
       "       [ 1.        ,  1.160021  ],\n",
       "       [ 1.        ,  1.2149128 ],\n",
       "       [ 1.        ,  1.8389611 ],\n",
       "       [ 1.        ,  2.999226  ],\n",
       "       [ 1.        ,  3.1411304 ],\n",
       "       [ 1.        ,  2.010895  ],\n",
       "       [ 1.        ,  2.5376573 ],\n",
       "       [ 1.        ,  2.6483002 ],\n",
       "       [ 1.        ,  2.7794402 ],\n",
       "       [ 1.        ,  1.4678743 ],\n",
       "       [ 1.        ,  2.5136561 ],\n",
       "       [ 1.        ,  2.6130066 ],\n",
       "       [ 1.        ,  2.677591  ],\n",
       "       [ 1.        ,  1.5623463 ],\n",
       "       [ 1.        ,  3.3028493 ],\n",
       "       [ 1.        ,  2.024193  ],\n",
       "       [ 1.        ,  1.7316556 ],\n",
       "       [ 1.        ,  2.8075938 ],\n",
       "       [ 1.        ,  1.5623463 ],\n",
       "       [ 1.        ,  3.246491  ],\n",
       "       [ 1.        ,  2.532903  ],\n",
       "       [ 1.        ,  2.830268  ],\n",
       "       [ 1.        ,  3.8210037 ],\n",
       "       [ 1.        ,  2.9074473 ],\n",
       "       [ 1.        ,  2.8825636 ],\n",
       "       [ 1.        ,  3.4719665 ]], dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0001259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98.34065"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(res[1]))\n",
    "np.var(res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.0591733 -0.5218844]\n",
      "[ 0.74342984 -0.4585815 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    beta = tfp.edward2.MultivariateNormalDiag(\n",
    "        loc=tf.zeros(2, dtype=tf.float32),\n",
    "        scale_identity_multiplier=tf.sqrt(2.), name='beta')\n",
    "    with tf.Session() as sess:\n",
    "        print(sess.run(beta))\n",
    "        print(sess.run(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0021605\n",
      "4.9917226\n",
      "(-5.0, -4.9986978)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    loc = tf.get_variable(        \n",
    "        'loc', (), initializer=tf.constant_initializer(5.), use_resource=True)\n",
    "    update_loc_op = tf.assign(loc, -5.)    \n",
    "    norm = tfp.edward2.Normal(loc=loc, scale=0.01).value\n",
    "    init_op = tf.group(tf.global_variables_initializer())\n",
    "graph.finalize()\n",
    "\n",
    "with graph.as_default(), tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(norm))\n",
    "    print(sess.run(norm))    \n",
    "    print(sess.run((update_loc_op, norm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.99481815, -0.00830093],\n",
       "       [-0.00830093,  2.01050811]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(beta.distribution.sample(200000).numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = 1 + tf.random_normal((), mean=5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=98, shape=(), dtype=float32, numpy=8.377048>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.022224\n",
      "5.022224\n",
      "-5.0\n",
      "5.022224\n",
      "tf.Tensor(5.004547, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "loc = tfe.Variable(initial_value=5.)\n",
    "norm = tfp.edward2.Normal(loc=loc, scale=0.01)\n",
    "\n",
    "print(norm.numpy())\n",
    "print(norm.numpy())\n",
    "\n",
    "loc.assign(-5.)\n",
    "\n",
    "print(loc.numpy())\n",
    "print(norm.numpy())\n",
    "print(norm.distribution.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=760, shape=(), dtype=float32, numpy=4.9960675>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.distribution.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=4.0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=443, shape=(), dtype=float32, numpy=5.008044>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.distribution.sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
