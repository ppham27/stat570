{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prostate Cancer\n",
    "\n",
    "In this notebook, we use blocked Gibbs sampling to examine the relationship between a prostate specific antigen and cancer volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  res = PandasDataFrame.from_items(items)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lcavol   lweight   age      lbph  svi       lcp  gleason  pgg45      lpsa\n",
       "0 -0.579818  2.769459  50.0 -1.386294  0.0 -1.386294      6.0    0.0 -0.430783\n",
       "1 -0.994252  3.319626  58.0 -1.386294  0.0 -1.386294      6.0    0.0 -0.162519\n",
       "2 -0.510826  2.691243  74.0 -1.386294  0.0 -1.386294      7.0   20.0 -0.162519\n",
       "3 -1.203973  3.282789  58.0 -1.386294  0.0 -1.386294      6.0    0.0 -0.162519\n",
       "4  0.751416  3.432373  62.0 -1.386294  0.0 -1.386294      6.0    0.0  0.371564"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import prostate\n",
    "from stat570.linear_model import linear_regression\n",
    "from stat570.mcmc import gibbs_sampling\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "prostate_data = prostate.load_data()\n",
    "prostate_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow `input_fn`\n",
    "\n",
    "We carry out our computations in TensorFlow, so we'll convert our data into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prostate_input_fn():\n",
    "    features = prostate_data.to_dict('list')\n",
    "    labels = features.pop('lpsa')\n",
    "    return tf.data.Dataset.from_tensors((features, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Functions\n",
    "\n",
    "In Gibbs sampling, we sample from the posterior conditional distributions. The inverse error variance (also known as precision) is gamma-distributed, and the coefficients are normally distributed. It's *blocked* Gibbs sampling since we draw both coefficients at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inverse_error_variance_dist(\n",
    "    prior_concentration, prior_rate, features, labels, beta):\n",
    "    \"\"\"Makes the the posterior distribution for inverse error variance.\"\"\"\n",
    "    with tf.name_scope('make_inverse_error_variance_dist', \n",
    "                       values=[\n",
    "                           prior_concentration,\n",
    "                           prior_rate,\n",
    "                           features,\n",
    "                           labels,\n",
    "                           beta,\n",
    "                       ]):\n",
    "        posterior_concentration = (\n",
    "            prior_concentration +\n",
    "            tf.divide(tf.cast(tf.shape(features)[0], tf.float32), 2.))\n",
    "        posterior_rate = (prior_rate +\n",
    "                          tf.nn.l2_loss(labels - tf.tensordot(features, beta, 1)))\n",
    "        \n",
    "        return tf.distributions.Gamma(\n",
    "            concentration=posterior_concentration, rate=posterior_rate,\n",
    "            name='posterior_inverse_error_variance')\n",
    "    \n",
    "def make_beta_dist(prior_mean, prior_variance, features, labels, inverse_error_variance):\n",
    "    \"\"\"Makes the posterior distribution for model coefficients.\"\"\"\n",
    "    shape = int(prior_mean.shape[0])\n",
    "    with tf.name_scope('make_beta_dist',\n",
    "                       values=[\n",
    "                           inverse_error_variance,\n",
    "                           features,\n",
    "                           labels,\n",
    "                           prior_mean,\n",
    "                           prior_variance,\n",
    "                       ]):\n",
    "        transposed_features = tf.transpose(features)\n",
    "        gramian_matrix = tf.matmul(transposed_features, features)\n",
    "        mle_mean = tf.squeeze(tf.linalg.cholesky_solve(\n",
    "            tf.linalg.cholesky(gramian_matrix),\n",
    "            tf.matmul(transposed_features, tf.expand_dims(labels, -1))))\n",
    "        mle_precision = gramian_matrix*inverse_error_variance            \n",
    "        \n",
    "        posterior_precision = mle_precision + tf.eye(shape)/prior_variance\n",
    "        posterior_covariance = tf.linalg.cholesky_solve(\n",
    "            tf.linalg.cholesky(posterior_precision), tf.eye(shape))\n",
    "        \n",
    "        posterior_mean = tf.tensordot(\n",
    "            tf.matmul(posterior_covariance, mle_precision),\n",
    "            mle_mean - prior_mean, axes=1) + prior_mean\n",
    "        \n",
    "        return tfp.distributions.MultivariateNormalFullCovariance(\n",
    "            loc=posterior_mean, covariance_matrix=posterior_covariance,\n",
    "            name='posterior_beta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Now, we specify the model. The generative process is specified in `forward`. We build our conditional disributions based on the data and use them to construct the transition kernel for Markov Chain Monte Carlo (MCMC) sampling.\n",
    "\n",
    "The code for [`gibbs_sampling.GibbsSamplingKernel`](https://github.com/ppham27/stat570/blob/master/stat570/mcmc/gibbs_sampling.py) can be on my [GitHub](https://github.com/ppham27/stat570/blob/master/stat570/mcmc/gibbs_sampling.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params, config):\n",
    "    del config\n",
    "    \n",
    "    prior_inverse_error_variance_concentration = (\n",
    "        params['prior']['inverse_error_variance']['concentration'])\n",
    "    prior_inverse_error_variance_rate = (\n",
    "        params['prior']['inverse_error_variance']['rate'])\n",
    "        \n",
    "    prior_beta_mean = tf.constant(params['prior']['beta']['mean'],\n",
    "                                  dtype=tf.float32)\n",
    "    prior_beta_variance = tf.constant(params['prior']['beta']['variance'],\n",
    "                                      dtype=tf.float32)\n",
    "    \n",
    "    def forward(features):\n",
    "        inverse_error_variance = tfp.edward2.Gamma(\n",
    "            concentration=prior_inverse_error_variance_concentration,\n",
    "            rate=prior_inverse_error_variance_rate,\n",
    "            name='inverse_error_variance')\n",
    "    \n",
    "        beta = tfp.edward2.MultivariateNormalDiag(\n",
    "            loc=prior_beta_mean,\n",
    "            scale_identity_multiplier=tf.sqrt(prior_beta_variance), name='beta')\n",
    "        \n",
    "        return tfp.edward2.Normal(\n",
    "            loc=tf.tensordot(features, beta, axes=1), scale=1/tf.sqrt(inverse_error_variance),\n",
    "            name='labels')\n",
    "    \n",
    "    features = tf.feature_column.input_layer(\n",
    "        features, [tf.feature_column.numeric_column('lcavol')])\n",
    "    features = tf.concat((tf.ones_like(features), features), axis=-1)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return forward(features).value\n",
    "    \n",
    "    log_joint_fn = functools.partial(\n",
    "        tfp.edward2.make_log_joint_fn(lambda: forward(features)),\n",
    "        labels=labels)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return log_joint_fn(labels=labels) # currently will error\n",
    "    \n",
    "    make_inverse_error_variance_dist_fn = functools.partial(\n",
    "        make_inverse_error_variance_dist,\n",
    "        prior_inverse_error_variance_concentration,\n",
    "        prior_inverse_error_variance_rate,\n",
    "        features, labels)\n",
    "    \n",
    "    make_beta_dist_fn = functools.partial(\n",
    "        make_beta_dist, prior_beta_mean, prior_beta_variance, features, labels)\n",
    "        \n",
    "    kernel = tfp.mcmc.MetropolisHastings(\n",
    "        inner_kernel=gibbs_sampling.GibbsSamplingKernel(\n",
    "            samplers=[\n",
    "                make_inverse_error_variance_dist_fn,\n",
    "                make_beta_dist_fn,\n",
    "            ],\n",
    "            target_log_prob_fn=lambda inverse_error_variance, beta: log_joint_fn(\n",
    "                inverse_error_variance=inverse_error_variance,\n",
    "                beta=beta)))\n",
    "    \n",
    "    samples, _ = tfp.mcmc.sample_chain(\n",
    "        num_results=params['mcmc']['num_results'],\n",
    "        current_state=(\n",
    "            params['mcmc']['initial_state']['inverse_error_variance'],\n",
    "            params['mcmc']['initial_state']['beta']),\n",
    "        kernel=kernel,\n",
    "        num_burnin_steps=500,\n",
    "        num_steps_between_results=1,  # One less the number of samplers.\n",
    "        parallel_iterations=1)\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running MCMC\n",
    "\n",
    "We start a TensorFlow session to run the chain. Parameters are taken from the homework. A gamma distribution with $0$ shape and $0$ rate is improper so very small values were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/stat570/linear_model/linear_regression.py:60: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  X = data_frame[covariates].as_matrix()\n",
      "/usr/local/lib/python3.5/dist-packages/stat570/linear_model/linear_regression.py:61: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  y = data_frame[response].as_matrix()\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_PARAMS = {\n",
    "    'prior': {\n",
    "        'inverse_error_variance': {\n",
    "            'concentration': 0.01,  # Also called shape and denoted alpha\n",
    "            'rate': 0.01,  # Usually denoted by beta.\n",
    "        },\n",
    "        'beta': {\n",
    "            'mean': [0., 0.],\n",
    "            'variance': 2.,  # Enforce equal variance and no covariance.\n",
    "        },\n",
    "    },\n",
    "    'mcmc': {\n",
    "        'num_results': 2048,\n",
    "        'initial_state': {\n",
    "            'inverse_error_variance': 1.,\n",
    "            'beta': [0., 0.],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "def get_mle_params():\n",
    "    mle_params = copy.deepcopy(DEFAULT_PARAMS)\n",
    "    mle_model = linear_regression.LinearRegression.from_data_frame(\n",
    "        prostate_data, ['lcavol'], 'lpsa')\n",
    "    mle_params['mcmc']['initial_state']['inverse_error_variance'] = (\n",
    "        1./mle_model.residual_variance_)\n",
    "    mle_params['mcmc']['initial_state']['beta'] = mle_model.coefficients_['estimate'].values\n",
    "    return mle_params\n",
    "\n",
    "def get_prior_params(params):\n",
    "    return params\n",
    "\n",
    "MLE_PARAMS = get_mle_params()\n",
    "PRIOR_PARAMS = get_prior_params(DEFAULT_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  return _inspect.getargspec(target)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    features, labels = prostate_input_fn().repeat().make_one_shot_iterator().get_next()\n",
    "    states_op = model_fn(\n",
    "        features, labels,\n",
    "        tf.estimator.ModeKeys.TRAIN, DEFAULT_PARAMS, tf.estimator.RunConfig())    \n",
    "    init_op = tf.group(tf.global_variables_initializer())\n",
    "graph.finalize()\n",
    "\n",
    "with graph.as_default(), tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    states = sess.run(states_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/stat570/linear_model/linear_regression.py:60: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  X = data_frame[covariates].as_matrix()\n",
      "/usr/local/lib/python3.5/dist-packages/stat570/linear_model/linear_regression.py:61: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  y = data_frame[response].as_matrix()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mcmc': {'initial_state': {'beta': [1.5072974615083856, 0.7193203895350354],\n",
       "   'inverse_error_variance': 1.6124984637190307},\n",
       "  'num_results': 2048},\n",
       " 'prior': {'beta': {'mean': [0.0, 0.0], 'variance': 2.0},\n",
       "  'inverse_error_variance': {'concentration': 0.01, 'rate': 0.01}}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "get_mle_params()    \n",
    "#mle_model.residual_variance_\n",
    "#MLE_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6069119\n",
      "[1.4968944 0.7228822]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(states[0]))\n",
    "print(np.mean(states[1], axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
