{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failure Stresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length (mm)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.247</td>\n",
       "      <td>2.640</td>\n",
       "      <td>2.842</td>\n",
       "      <td>2.908</td>\n",
       "      <td>3.099</td>\n",
       "      <td>3.126</td>\n",
       "      <td>3.245</td>\n",
       "      <td>3.328</td>\n",
       "      <td>3.355</td>\n",
       "      <td>3.383</td>\n",
       "      <td>3.572</td>\n",
       "      <td>3.581</td>\n",
       "      <td>3.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.901</td>\n",
       "      <td>2.132</td>\n",
       "      <td>2.203</td>\n",
       "      <td>2.228</td>\n",
       "      <td>2.257</td>\n",
       "      <td>2.350</td>\n",
       "      <td>2.361</td>\n",
       "      <td>2.396</td>\n",
       "      <td>2.397</td>\n",
       "      <td>2.445</td>\n",
       "      <td>2.454</td>\n",
       "      <td>2.454</td>\n",
       "      <td>2.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.312</td>\n",
       "      <td>1.314</td>\n",
       "      <td>1.479</td>\n",
       "      <td>1.552</td>\n",
       "      <td>1.700</td>\n",
       "      <td>1.803</td>\n",
       "      <td>1.861</td>\n",
       "      <td>1.865</td>\n",
       "      <td>1.944</td>\n",
       "      <td>1.958</td>\n",
       "      <td>1.966</td>\n",
       "      <td>1.997</td>\n",
       "      <td>2.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.339</td>\n",
       "      <td>1.434</td>\n",
       "      <td>1.549</td>\n",
       "      <td>1.574</td>\n",
       "      <td>1.589</td>\n",
       "      <td>1.613</td>\n",
       "      <td>1.746</td>\n",
       "      <td>1.753</td>\n",
       "      <td>1.764</td>\n",
       "      <td>1.807</td>\n",
       "      <td>1.812</td>\n",
       "      <td>1.840</td>\n",
       "      <td>1.852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0      1      2      3      4      5      6      7      8   \\\n",
       "Length (mm)                                                                  \n",
       "1            2.247  2.640  2.842  2.908  3.099  3.126  3.245  3.328  3.355   \n",
       "10           1.901  2.132  2.203  2.228  2.257  2.350  2.361  2.396  2.397   \n",
       "20           1.312  1.314  1.479  1.552  1.700  1.803  1.861  1.865  1.944   \n",
       "50           1.339  1.434  1.549  1.574  1.589  1.613  1.746  1.753  1.764   \n",
       "\n",
       "                9      10     11     12  \n",
       "Length (mm)                              \n",
       "1            3.383  3.572  3.581  3.681  \n",
       "10           2.445  2.454  2.454  2.474  \n",
       "20           1.958  1.966  1.997  2.006  \n",
       "50           1.807  1.812  1.840  1.852  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import functools\n",
    "import unittest\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import special\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from stat570 import datasets\n",
    "\n",
    "failure_stresses = datasets.failure_stresses.load_data()\n",
    "failure_stresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Specification\n",
    "\n",
    "We specify priors for the scale, $\\alpha \\sim \\operatorname{LogNormal}\\left(\\mu_\\alpha, \\sigma_\\alpha\\right)$, and the concentration (or shape), $\\eta \\sim \\operatorname{LogNormal}\\left(\\mu_\\eta, \\sigma_\\eta\\right)$ for Weibull distribution: $Y \\sim \\operatorname{Weibull}\\left(\\alpha,\\eta\\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeibullModel:\n",
    "    def __init__(self,\n",
    "                 prior_alpha_mean, prior_alpha_standard_deviation,\n",
    "                 prior_eta_mean, prior_eta_standard_deviation) -> None:\n",
    "        self._prior_alpha_mean = prior_alpha_mean\n",
    "        self._prior_alpha_standard_deviation = prior_alpha_standard_deviation\n",
    "        self._prior_eta_mean = prior_eta_mean\n",
    "        self._prior_eta_standard_deviation = prior_eta_standard_deviation\n",
    "    \n",
    "    def __call__(self, shape=()):\n",
    "        alpha = tfp.edward2.as_random_variable(tfp.distributions.LogNormal(\n",
    "            loc=self._prior_alpha_mean,\n",
    "            scale=self._prior_alpha_standard_deviation,\n",
    "            name='alpha'))\n",
    "        \n",
    "        eta = tfp.edward2.as_random_variable(tfp.distributions.LogNormal(\n",
    "            loc=self._prior_eta_mean,\n",
    "            scale=self._prior_eta_standard_deviation,\n",
    "            name='eta'))\n",
    "        \n",
    "        return tfp.edward2.as_random_variable(tfp.distributions.TransformedDistribution(\n",
    "            distribution=tfp.distributions.Uniform(),\n",
    "            bijector=tfp.bijectors.Invert(\n",
    "                tfp.bijectors.Weibull(scale=alpha, concentration=eta)),\n",
    "            name='response'), sample_shape=shape)\n",
    "    \n",
    "    def make_log_joint_fn(self, labels):\n",
    "        return functools.partial(\n",
    "            tfp.edward2.make_log_joint_fn(lambda: self(tf.shape(labels))),\n",
    "            response=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "We construct a posterior over the model parameters and sample with MCMC to do inference on the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params, config):\n",
    "    del features, config\n",
    "    \n",
    "    model = WeibullModel(tf.convert_to_tensor(params['prior']['alpha']['mean'], tf.float32),\n",
    "                         tf.convert_to_tensor(params['prior']['alpha']['standard_deviation'], tf.float32),\n",
    "                         tf.convert_to_tensor(params['prior']['eta']['mean'], tf.float32),\n",
    "                         tf.convert_to_tensor(params['prior']['eta']['standard_deviation'], tf.float32))\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return model().value\n",
    "    \n",
    "    log_joint_fn = model.make_log_joint_fn(labels)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return log_joint_fn() # won't work\n",
    "    \n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "        \n",
    "    kernel = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "        num_leapfrog_steps=params['mcmc']['num_leapfrog_steps'],\n",
    "        step_size=tf.get_variable('hmc_step_size_{}'.format(params['replica']),\n",
    "                                  initializer=params['mcmc']['step_size'],\n",
    "                                  use_resource=True, trainable=False),\n",
    "        step_size_update_fn=tfp.mcmc.make_simple_step_size_update_policy(),\n",
    "        target_log_prob_fn=lambda alpha, eta: log_joint_fn(alpha=alpha, eta=eta))\n",
    "    \n",
    "    states, _ = tfp.mcmc.sample_chain(\n",
    "        kernel=kernel,  \n",
    "        current_state=(\n",
    "            tf.convert_to_tensor(params['mcmc']['initial_state']['alpha'], tf.float32),\n",
    "            tf.convert_to_tensor(params['mcmc']['initial_state']['eta'], tf.float32)),\n",
    "        num_results=params['mcmc']['num_results'],\n",
    "        num_burnin_steps=params['mcmc']['num_burnin_steps'],\n",
    "        num_steps_between_results=params['mcmc']['num_steps_between_results'],\n",
    "        parallel_iterations=1)\n",
    "    return states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Prior Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.003s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "def compute_log_norm_prior(l, u, density):\n",
    "    \"\"\"Computes the hyperparameters for lognormal distribution.\n",
    "    \n",
    "    Let X = exp(mu + sigma*Z). Computes mu and sigma such that\n",
    "    P(l <= X <= u) = density.\n",
    "    \"\"\"\n",
    "    tail_density = (1 - density)/2\n",
    "    a, b = stats.norm.ppf(tail_density), stats.norm.ppf(1 - tail_density)    \n",
    "    sigma = np.log(u/l)/(b - a)\n",
    "    mu = np.log(u) - b*sigma\n",
    "    return mu, sigma\n",
    "\n",
    "class ComputeLogNormPrior(unittest.TestCase):    \n",
    "    def test_compute_log_norm_prior(self):\n",
    "        l, u = stats.uniform.rvs(0, 10), stats.uniform.rvs(20, 30)\n",
    "        mu, sigma = compute_log_norm_prior(l, u, 0.9)\n",
    "        self.assertAlmostEqual(\n",
    "            stats.lognorm.cdf(l, scale=np.exp(mu), s=sigma), 0.05)\n",
    "        self.assertAlmostEqual(\n",
    "            stats.lognorm.sf(u, scale=np.exp(mu), s=sigma), 0.05)\n",
    "\n",
    "unittest.main(argv=['_'], exit=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose parameters with the values in the homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mcmc': {'initial_state': {'alpha': 5.95716492040242,\n",
       "   'eta': 11.977030327078252},\n",
       "  'num_burnin_steps': 1024,\n",
       "  'num_leapfrog_steps': 3,\n",
       "  'num_results': 2048,\n",
       "  'num_steps_between_results': 3,\n",
       "  'step_size': 0.01},\n",
       " 'prior': {'alpha': {'mean': 0.6931471805599454,\n",
       "   'standard_deviation': 0.4214035639417993},\n",
       "  'eta': {'mean': 1.3540251005511053,\n",
       "   'standard_deviation': 1.2445923744018637}},\n",
       " 'replica': 0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAMS = {\n",
    "    'prior': {\n",
    "        'eta': {'mean': 0., 'standard_deviation': 1.},\n",
    "        'alpha': {'mean': 0., 'standard_deviation': 1.},\n",
    "    },\n",
    "    'mcmc': {\n",
    "        'num_burnin_steps': 1024,\n",
    "        'num_leapfrog_steps': 3,\n",
    "        'num_results': 2048,\n",
    "        'num_steps_between_results': 3,\n",
    "        'step_size': 0.01,\n",
    "        'initial_state': {\n",
    "            'alpha': 5.,\n",
    "            'eta': 2.,\n",
    "        },\n",
    "    },\n",
    "    'replica': 0,\n",
    "}\n",
    "\n",
    "# Specify priors according to tail probabilities.\n",
    "PARAMS['prior']['alpha']['mean'], PARAMS['prior']['alpha']['standard_deviation'] = (\n",
    "    compute_log_norm_prior(1., 4., 0.9))\n",
    "PARAMS['prior']['eta']['mean'], PARAMS['prior']['eta']['standard_deviation'] = (\n",
    "    compute_log_norm_prior(1./2., 30., 0.9))\n",
    "# Generate an initial state from the priors.\n",
    "PARAMS['mcmc']['initial_state']['alpha'] = stats.lognorm.rvs(\n",
    "    scale=np.exp(PARAMS['prior']['alpha']['mean']),\n",
    "    s=PARAMS['prior']['alpha']['standard_deviation'])\n",
    "PARAMS['mcmc']['initial_state']['eta'] = stats.lognorm.rvs(\n",
    "    scale=np.exp(PARAMS['prior']['eta']['mean']),\n",
    "    s=PARAMS['prior']['eta']['standard_deviation'])\n",
    "\n",
    "PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Chains\n",
    "\n",
    "We create a chain for each row data and run the chains in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(replica):\n",
    "    params = copy.deepcopy(PARAMS)\n",
    "    params['replica'] = replica\n",
    "    return params\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():    \n",
    "    features = tf.placeholder(name='features', dtype=tf.float32, shape=(None))\n",
    "    chain_ops = {\n",
    "        idx: model_fn(features, tf.constant(data.values.astype(np.float32)),\n",
    "                      tf.estimator.ModeKeys.TRAIN, get_params(idx), tf.estimator.RunConfig())\n",
    "        for idx, data in failure_stresses.iterrows()\n",
    "    }\n",
    "    init_op = tf.group(tf.global_variables_initializer())\n",
    "graph.finalize()\n",
    "\n",
    "with graph.as_default(), tf.Session() as sess:\n",
    "    sess.run(init_op)    \n",
    "    states = sess.run(chain_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3.1309266 [3.3081036 9.301485 ]\n",
      "10 2.3222566 [ 2.3833928 21.048515 ]\n",
      "20 1.766275 [ 1.8626783 10.041165 ]\n",
      "50 1.655488 [ 1.7312734 11.787451 ]\n"
     ]
    }
   ],
   "source": [
    "for i, samples in states.items():\n",
    "    print(i, np.mean(samples[0]*special.gamma(1 + 1/samples[1])), np.mean(samples, axis=-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
