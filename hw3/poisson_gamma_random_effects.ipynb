{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'raise', 'invalid': 'raise', 'over': 'warn', 'under': 'ignore'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import linalg\n",
    "from scipy import stats\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "np.seterr(divide='raise', invalid='raise', over='warn', under='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BETA_0 = -2\n",
    "BETA_1 = np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(b, n):\n",
    "    x = stats.norm.rvs(loc=2, scale=1, size=n)    \n",
    "    mu = np.exp(x*BETA_1 + BETA_0)\n",
    "    theta = stats.gamma.rvs(b, scale=1/b, size=n)\n",
    "    return x, stats.poisson.rvs(theta*mu, size=n)\n",
    "\n",
    "def estimate_by_poisson_model(x, y):\n",
    "    def score(beta):\n",
    "        beta_0 = beta[0]\n",
    "        beta_1 = beta[1]\n",
    "        return np.array([\n",
    "            np.sum(y - np.exp(beta_0 + beta_1*x)),\n",
    "            np.sum(x*y - x*np.exp(beta_0 + beta_1*x)),\n",
    "        ])\n",
    "    \n",
    "    beta_hat = optimize.root(score, np.array([-2, np.log(2)]))['x']        \n",
    "    mu_hat = np.exp(beta_hat[0] + beta_hat[1]*x)\n",
    "    \n",
    "    fisher_determinant = np.sum(mu_hat)*np.sum(x*x*mu_hat) - np.square(np.sum(x*mu_hat))\n",
    "    beta_hat_variance = np.array([\n",
    "        [np.sum(x*x*mu_hat), -np.sum(x*mu_hat)],\n",
    "        [-np.sum(x*mu_hat), np.sum(mu_hat)]\n",
    "    ])/fisher_determinant\n",
    "    \n",
    "    return beta_hat, beta_hat_variance\n",
    "\n",
    "def estimate_by_quasi_likelihood(x, y):\n",
    "    beta_hat, beta_hat_variance = estimate_by_poisson_model(x, y)\n",
    "    \n",
    "    mu_hat = np.exp(beta_hat[0] + beta_hat[1]*x)\n",
    "    if np.any(mu_hat == 0):\n",
    "        print(beta_hat)\n",
    "        print(x)\n",
    "        print(y)\n",
    "    alpha_hat = np.sum(np.square(y - mu_hat)/mu_hat)/(len(y) - 2)\n",
    "    \n",
    "    return beta_hat, alpha_hat*beta_hat_variance    \n",
    "\n",
    "def estimate_by_sandwich(x, y):\n",
    "    beta_hat, beta_hat_variance = estimate_by_poisson_model(x, y)\n",
    "    \n",
    "    mu_hat = np.exp(beta_hat[0] + beta_hat[1]*x)\n",
    "    #residuals = np.expand_dims((y - mu_hat)/mu_hat, -1)\n",
    "    #residuals = residuals.dot(residuals.T)\n",
    "    #d_transpose = np.array([mu_hat, x*mu_hat])     \n",
    "    #b_hat = d_transpose.dot(residuals).dot(d_transpose.T)\n",
    "    b_hat = np.sum(\n",
    "        np.square(y - mu_hat)[:,np.newaxis,np.newaxis]*np.transpose(np.array([\n",
    "            [np.ones_like(y), x],\n",
    "            [x, x*x],\n",
    "        ]), axes=[2,1,0]),\n",
    "        axis=0)\n",
    "    \n",
    "    return beta_hat, beta_hat_variance.dot(b_hat).dot(beta_hat_variance.T)\n",
    "\n",
    "def is_covered_by_confidence_interval(estimates, actual, variances, level=0.95):\n",
    "    return np.abs(estimates - actual) <= stats.norm.isf((1 - level)/2)*np.sqrt(np.diag(variances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = pd.DataFrame(index=pd.MultiIndex.from_product([\n",
    "    [0.2, 1, 10, 1000],\n",
    "    [10, 20, 50, 100, 250, 1000],\n",
    "    #[0.2], [10],\n",
    "], names=['b', 'n']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b=0.2, n=10\n",
      "[0.7795 0.7649]\n",
      "[0.8933 0.894 ]\n",
      "[0.7957 0.7287]\n",
      "b=0.2, n=20\n",
      "[0.7451 0.6921]\n",
      "[0.9203 0.8959]\n",
      "[0.8294 0.7384]\n",
      "b=0.2, n=50\n",
      "[0.6952 0.6257]\n",
      "[0.9324 0.8923]\n",
      "[0.8686 0.8012]\n",
      "b=0.2, n=100\n",
      "[0.6552 0.5728]\n",
      "[0.928  0.8768]\n",
      "[0.8804 0.8333]\n",
      "b=0.2, n=250\n",
      "[0.6291 0.5449]\n",
      "[0.927  0.8668]\n",
      "[0.9035 0.8756]\n",
      "b=0.2, n=1000\n",
      "[0.5978 0.5124]\n",
      "[0.9146 0.8468]\n",
      "[0.9311 0.9159]\n",
      "b=1.0, n=10\n",
      "[0.913  0.9054]\n",
      "[0.9065 0.9052]\n",
      "[0.8441 0.8022]\n",
      "b=1.0, n=20\n",
      "[0.8879 0.8582]\n",
      "[0.9288 0.9113]\n",
      "[0.8798 0.8268]\n",
      "b=1.0, n=50\n",
      "[0.8696 0.8285]\n",
      "[0.9359 0.9104]\n",
      "[0.9016 0.8718]\n",
      "b=1.0, n=100\n",
      "[0.8523 0.8095]\n",
      "[0.9322 0.8982]\n",
      "[0.9127 0.8909]\n",
      "b=1.0, n=250\n",
      "[0.8453 0.7938]\n",
      "[0.9358 0.9   ]\n",
      "[0.933 0.918]\n",
      "b=1.0, n=1000\n",
      "[0.8339 0.7847]\n",
      "[0.9262 0.8891]\n",
      "[0.9434 0.9379]\n",
      "b=10.0, n=10\n",
      "[0.9552 0.9609]\n",
      "[0.9087 0.9124]\n",
      "[0.8588 0.8337]\n",
      "b=10.0, n=20\n",
      "[0.9487 0.9462]\n",
      "[0.9304 0.9289]\n",
      "[0.9021 0.875 ]\n",
      "b=10.0, n=50\n",
      "[0.9348 0.9346]\n",
      "[0.9359 0.9337]\n",
      "[0.9154 0.9008]\n",
      "b=10.0, n=100\n",
      "[0.9385 0.9311]\n",
      "[0.9426 0.9357]\n",
      "[0.929  0.9174]\n",
      "b=10.0, n=250\n",
      "[0.937  0.9336]\n",
      "[0.9436 0.9414]\n",
      "[0.9384 0.9345]\n",
      "b=10.0, n=1000\n",
      "[0.9396 0.9319]\n",
      "[0.9466 0.9387]\n",
      "[0.9485 0.942 ]\n",
      "b=1000.0, n=10\n",
      "[0.9603 0.9712]\n",
      "[0.911  0.9147]\n",
      "[0.8629 0.8356]\n",
      "b=1000.0, n=20\n",
      "[0.9526 0.9555]\n",
      "[0.9342 0.9331]\n",
      "[0.9048 0.881 ]\n",
      "b=1000.0, n=50\n",
      "[0.9519 0.9518]\n",
      "[0.9456 0.9456]\n",
      "[0.9269 0.9106]\n",
      "b=1000.0, n=100\n",
      "[0.9516 0.9529]\n",
      "[0.9469 0.9502]\n",
      "[0.9371 0.9268]\n",
      "b=1000.0, n=250\n",
      "[0.9497 0.9522]\n",
      "[0.9494 0.9523]\n",
      "[0.9426 0.941 ]\n",
      "b=1000.0, n=1000\n",
      "[0.9516 0.9509]\n",
      "[0.9502 0.9502]\n",
      "[0.949 0.948]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from scipy import optimize\n",
    "\n",
    "np.random.seed(2018)\n",
    "for b, n in experiments.index:\n",
    "    print('b={}, n={}'.format(b, n))\n",
    "    poisson_estimates = []\n",
    "    poisson_variances = []\n",
    "    \n",
    "    quasi_likelihood_estimates = []\n",
    "    quasi_likelihood_variances = []\n",
    "    \n",
    "    sandwich_estimates = []\n",
    "    sandwich_variances = []\n",
    "    \n",
    "    for i in range(10000):\n",
    "        x, y = generate_data(b, n)\n",
    "        while np.sum(y > 0) < 2:\n",
    "            #logging.getLogger().warning('Regenerating data.')\n",
    "            x, y = generate_data(b, n)\n",
    "\n",
    "        poisson_estimate, poisson_variance = estimate_by_poisson_model(x, y)            \n",
    "        quasi_likelihood_estimate, quasi_likelihood_variance = estimate_by_quasi_likelihood(x, y)\n",
    "        sandwich_estimate, sandwich_variance = estimate_by_sandwich(x, y)\n",
    "                    \n",
    "        poisson_estimates.append(poisson_estimate)\n",
    "        poisson_variances.append(poisson_variance)        \n",
    "        \n",
    "        quasi_likelihood_estimates.append(quasi_likelihood_estimate)\n",
    "        quasi_likelihood_variances.append(quasi_likelihood_variance)\n",
    "        \n",
    "        sandwich_estimates.append(sandwich_estimate)\n",
    "        sandwich_variances.append(sandwich_variance)\n",
    "        \n",
    "    poisson_estimates = np.array(poisson_estimates)\n",
    "    poisson_variances = np.array(poisson_variances)\n",
    "    \n",
    "    quasi_likelihood_estimates = np.array(quasi_likelihood_estimates)\n",
    "    quasi_likelihood_variances = np.array(quasi_likelihood_variances)\n",
    "    \n",
    "    sandwich_estimates = np.array(sandwich_estimates)\n",
    "    sandwich_variances = np.array(sandwich_variances)\n",
    "    \n",
    "    is_covered_by_confidence_interval_vectorized = (\n",
    "        np.vectorize(\n",
    "            lambda e, v: is_covered_by_confidence_interval(\n",
    "                e, np.array([BETA_0, BETA_1]), v),\n",
    "            otypes=[np.bool],\n",
    "            signature='(i),(i,i)->(i)'))\n",
    "    \n",
    "    poisson_coverage = np.sum(is_covered_by_confidence_interval_vectorized(\n",
    "        poisson_estimates, poisson_variances), axis=0)/len(poisson_estimates)\n",
    "    \n",
    "    quasi_likelihood_coverage = np.sum(is_covered_by_confidence_interval_vectorized(\n",
    "        quasi_likelihood_estimates, quasi_likelihood_variances), axis=0)/len(quasi_likelihood_estimates)\n",
    "    \n",
    "    sandwich_coverage = np.sum(is_covered_by_confidence_interval_vectorized(\n",
    "        sandwich_estimates, sandwich_variances), axis=0)/len(sandwich_estimates)\n",
    "    \n",
    "    print(poisson_coverage)\n",
    "    print(quasi_likelihood_coverage)\n",
    "    print(sandwich_coverage)\n",
    "    \n",
    "    #print(np.sum(np.abs(estimates[:,0] - BETA_0) <= np.sqrt(variances[:,0])*stats.norm.isf((1 - 0.95)/2)))\n",
    "    #print(np.sum(np.abs(estimates[:,1] - BETA_1) <= np.sqrt(variances[:,1])*stats.norm.isf((1 - 0.95)/2)))    \n",
    "    #print(np.mean(estimates, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
