\documentclass[letterpaper,11pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage[hmargin=1.25in,vmargin=1in]{geometry}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{subcaption}

\title{Final: STAT 570}
\author{Philip Pham}
\date{\today}

\begin{document}
\maketitle

Consider the failure time data in Table \ref{tab:failure_time_data}.

\begin{enumerate}
\item We describe a simple model for these data. Let $p$ ($0 < p < 1$) denote
  the weekly failure probability, i.e., the probability of failure during any
  week, and $T$ the random variable describing the week at which failure
  occurred. Then $T$ may be modeled as a geometric random variable:
  \begin{equation}
    \mathbb{P}\left(T = t \mid p\right)
    = \begin{cases}
      p\left(1-p\right)^{t-1}, &t=1,2,\ldots; \\
      0,&\text{otherwise}.      
    \end{cases}
    \label{eqn:p1_model}
  \end{equation}

  Let $Y_t$ represent the number of components that fail in week $t$,
  $t = 1,2,\ldots,N$, and $Y_{N+1}$ the number of components that have not failed
  by week $N$.

  \begin{enumerate}
  \item Show that the likelihood function is
    \begin{equation}
      L\left(p\right) =
      \left[\left(1 - p\right)^N\right]^{Y_{N+1}}
      \prod_{t=1}^N\left[
        p\left(1 - p\right)^{t-1}
      \right]^{Y_t}.
      \label{eqn:p1_likelihood}      
    \end{equation}
    \begin{description}
    \item[Solution:] An individual component's failure week has distribution
      $\operatorname{Geometric}\left(p\right)$. The probability that a single
      component fails in week $t$ is the probability that it survived $t - 1$
      weeks and failed on week $t$, which is $p\left(1 - p\right)^{t-1}$. There
      are $Y_t$ such components, which gives us the factors for
      $t = 1,2,\ldots,N$.

      The probability that a component fails at a later date is
      \[
        \left(1 - p\right)^N\sum_{k=1}^\infty p\left(1-p\right)^{k-1}
        =
        \left(1 - p\right)^N\frac{p}{1 - \left(1 - p\right)}
        =
        \left(1 - p\right)^N,
      \]
      which gives us the remaining factor. There are $Y_{N+1}$ remaining
      components, so
      \[
        L\left(p\right) =
        \left\{
          \prod_{t=1}^N \left[
            p\left(1 - p \right)^{t-1}
          \right]^{Y_t}
        \right\}
        \times
        \left[\left(1-p\right)^N\right]^{Y_{N+1}}.
      \]
    \end{description}
  \item Find an expression for the MLE $\hat{p}$.
    \begin{description}
    \item[Solution:] 
      The score function is
      \begin{align}
        S\left(p\right)
        &= \frac{\partial}{\partial p}\log L\left(p\right) \nonumber\\
        &= \frac{\partial}{\partial p}\left[
          NY_{N + 1}\log\left(1 - p\right)
          + \sum_{t=1}^N Y_t\left(
          \log p + \left(t - 1\right)
          \log\left(1 - p\right)
          \right)
          \right]\nonumber\\
        &= -\frac{NY_{N+1}}{1 - p}
          + \sum_{t=1}^N Y_t\left(
          \frac{1}{p}
          -
          \frac{t - 1}{1 - p}
          \right)
        = -\frac{NY_{N+1}}{1 - p}
          + \sum_{t=1}^N Y_t
          \frac{1-pt}{p\left(1 - p\right)}.
          \label{eqn:p1_score}
      \end{align}

      Solving for $S\left(\hat{p}\right) = 0$, we find the MLE:
      \begin{equation}
        \hat{p}\left(
          NY_{N+1} + \sum_{t=1}^{N}tY_t
        \right) = \sum_{t=1}^N Y_t
        \implies
        \boxed{
          \hat{p} = \frac{\sum_{t=1}^N Y_t}
          {NY_{N+1} + \sum_{t=1}^{N}tY_t}.
        }
        \label{eqn:p1_mle}
      \end{equation}
    \end{description}
  \item Find the form of the observed information and hence the asymptotic
    variance of the maximum likelihood estimate (MLE).
    \begin{description}
    \item[Solution:] Using Equation \ref{eqn:p1_score}, the expected observed
      information is
      \begin{align}
        I\left(p\right)
        &= \mathbb{E}\left[-\frac{\partial}{\partial p}S\left(p\right) \mid p\right]
          \nonumber\\
        &= \frac{N\mathbb{E}\left[Y_{N+1} \mid p\right]}{(1-p)^2}
          + \sum_{t=1}^N\mathbb{E}\left[Y_t \mid p\right]
          \left(
          \frac{1}{p^2} + \frac{t-1}{\left(1-p\right)^2}
          \right)
          \nonumber \\
        &= n\frac{N\left(1-p\right)^N}{(1-p)^2}
          + np\sum_{t=1}^N
          \left(1 - p\right)^{t-1}
          \left(
          \frac{1}{p^2} + \frac{t-1}{\left(1-p\right)^2}
          \right)
          \nonumber \\
        &= n\left[
          \frac{\left(1-p\right)^N}{(1-p)^2}
          +
          \frac{1 - \left(1 - p\right)^N}{p^2}
          +
          \frac{(1-p) - (1-p)^N}{p(1-p)^2}
          \right] \nonumber \\
        &= \boxed{n\frac{1 - \left(1 - p\right)^N}
          {p^2\left(1 - p\right)},} \label{eqn:p1_fisher_information}
      \end{align}
      where $n = Y_{N+1} + \sum_{t=1}^N Y_t$.

      From Equation \ref{eqn:p1_fisher_information}, the asymptotic variance of
      $\hat{p}$ is
      \begin{equation}
        \operatorname{var}\left(\hat{p}\right)
        \approx
        I\left(\hat{p}\right)^{-1} = \frac{1}{n} \times
        \frac{\hat{p}^2\left(1-\hat{p}\right)}
        {1 - \left(1-\hat{p}\right)^N}
        \label{eqn:p1_variance}
      \end{equation}
      by asymptotic normality of the MLE.
    \end{description}
  \end{enumerate}
\end{enumerate}

\begin{table}
  \centering
  \input{failure_time_data.tex}
  \caption{Time until failure for $n = 485$ components, along with average weekly
    temperature.}
  \label{tab:failure_time_data}
\end{table}
\end{document}
